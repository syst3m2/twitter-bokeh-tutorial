{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take your Twitter API Bearer Token and set as an Operating System environment variable via the command line.\n",
    "# It is not advisable to store the token itself in the application code for security purposes\n",
    "\n",
    "import os\n",
    "os.environ['TOKEN'] = r'<BEARER-TOKEN>'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code on how to use Python to query the Twitter API was referenced from \n",
    "\n",
    "https://towardsdatascience.com/an-extensive-guide-to-collecting-tweets-from-twitter-api-v2-for-academic-research-using-python-3-518fcb71df2a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install bokeh\n",
    "!pip install jupyter-server-proxy && jupyter serverextension enable --py jupyter-server-proxy\n",
    "!jupyter labextension install @jupyterlab/server-proxy\n",
    "!pip install bokeh_wordcloud2\n",
    "!pip install sqlalchemy\n",
    "!pip install nltk\n",
    "!pip install tweet-preprocessor\n",
    "!pip install wordcloud\n",
    "!pip install dash\n",
    "!pip install jupyter-dash\n",
    "!pip install dash-bootstrap-components\n",
    "!pip install -q transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For sending GET requests from the API\n",
    "import requests\n",
    "\n",
    "# For dealing with json responses we receive from the API\n",
    "import json\n",
    "\n",
    "# For displaying the data after\n",
    "import pandas as pd\n",
    "\n",
    "# For managing the sqlite database\n",
    "import sqlite3\n",
    "from sqlite3 import Error\n",
    "\n",
    "# An additional framework for managing databases using an ORM\n",
    "from sqlalchemy import create_engine, Integer, JSON, Column, Sequence, select, MetaData\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from sqlalchemy.ext.declarative import declarative_base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 1: Data stream to database.\n",
    "\n",
    "This section of the notebook shows how you would code a script that can pull data from the Twitter API and store it into a database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions that will be used in part one\n",
    "\n",
    "# Gets the bearer token from the OS environment variable\n",
    "def auth():\n",
    "    return os.getenv('TOKEN')\n",
    "\n",
    "# Creates the header to authorize requests to the API\n",
    "def create_headers(bearer_token):\n",
    "    headers = {\"Authorization\": \"Bearer {}\".format(bearer_token)}\n",
    "    return headers\n",
    "\n",
    "# Creates the full URL for the API request with the desired parameters\n",
    "def create_url(keyword, start_date, end_date, max_results = 10):\n",
    "    \n",
    "    search_url = \"https://api.twitter.com/2/tweets/search/recent\" #Change to the endpoint you want to collect data from\n",
    "\n",
    "    #change params based on the endpoint you are using\n",
    "    query_params = {'query': keyword,\n",
    "                    'start_time': start_date,\n",
    "                    'end_time': end_date,\n",
    "                    'max_results': max_results,\n",
    "                    'expansions': 'author_id,in_reply_to_user_id,geo.place_id',\n",
    "                    'tweet.fields': 'id,text,author_id,in_reply_to_user_id,geo,conversation_id,created_at,lang,public_metrics,referenced_tweets,reply_settings,source',\n",
    "                    'user.fields': 'id,name,username,created_at,description,public_metrics,verified',\n",
    "                    'place.fields': 'full_name,id,country,country_code,geo,name,place_type',\n",
    "                    'next_token': {}}\n",
    "    return (search_url, query_params)\n",
    "\n",
    "# Sends request to the specified API endpoints and returns the response\n",
    "def connect_to_endpoint(url, headers, params, next_token = None):\n",
    "    params['next_token'] = next_token   #params object received from create_url function\n",
    "    response = requests.request(\"GET\", url, headers = headers, params = params)\n",
    "    print(\"Endpoint Response Code: \" + str(response.status_code))\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(response.status_code, response.text)\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set input variables for all requests\n",
    "# We will query all tweets about the Navy for the last week\n",
    "\n",
    "bearer_token = auth()\n",
    "headers = create_headers(bearer_token)\n",
    "keyword = \"Navy\"\n",
    "start_time = \"2022-11-13T00:00:00.000Z\"\n",
    "end_time = \"2022-11-18T00:00:00.000Z\"\n",
    "max_results = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the request URL and get the response.\n",
    "\n",
    "url = create_url(keyword, start_time,end_time, max_results)\n",
    "twitter_response = connect_to_endpoint(url[0], headers, url[1])\n",
    "\n",
    "print(json.dumps(twitter_response, indent=4, sort_keys=True)[:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have some data, let's store it in a database for future use. \n",
    "\n",
    "The following code was referenced from\n",
    "https://www.sqlitetutorial.net/sqlite-python/creating-database/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n",
      "Database created\n",
      "Connection established\n",
      "Table created\n",
      "[('twitter',)]\n"
     ]
    }
   ],
   "source": [
    "# Save the results to an sqlite database\n",
    "\n",
    "def create_database(db_file):\n",
    "    \"\"\" create an SQLite database \"\"\"\n",
    "    conn = None\n",
    "    try:\n",
    "        conn = sqlite3.connect(db_file)\n",
    "        print(sqlite3.version)\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "    finally:\n",
    "        if conn:\n",
    "            conn.close()\n",
    "\n",
    "def create_connection(db_file):\n",
    "    \"\"\" create a database connection to the SQLite database\n",
    "        specified by db_file\n",
    "    :param db_file: database file\n",
    "    :return: Connection object and cursor or None\n",
    "    \"\"\"\n",
    "    conn = None\n",
    "    try:\n",
    "        conn = sqlite3.connect(db_file)\n",
    "        c = conn.cursor()\n",
    "        return conn, c\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "\n",
    "    return conn\n",
    "\n",
    "def create_table(c, create_table_sql):\n",
    "    \"\"\" create a table from the create_table_sql statement\n",
    "    :param c: Cursor object\n",
    "    :param create_table_sql: a CREATE TABLE statement\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    try:\n",
    "        c.execute(create_table_sql)\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "\n",
    "def execute_sql(c, sql_cmd):\n",
    "    \"\"\" create a table from the create_table_sql statement\n",
    "    :param c: Cursor object\n",
    "    :param sql_cmd: an SQL statement\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    try:\n",
    "        c.execute(sql_cmd)\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "\n",
    "# Create our database\n",
    "create_database(r\"twitter.db\")\n",
    "print(\"Database created\")\n",
    "\n",
    "# Establish a connection to the database, which we can now read and write from\n",
    "conn, c = create_connection(r\"twitter.db\")\n",
    "print(\"Connection established\")\n",
    "\n",
    "# Initiatialize what tables are in the database\n",
    "\n",
    "# This is our SQL statement to create a table to store our twitter data in plaintext\n",
    "sql_create_twitter_table = \"\"\" CREATE TABLE IF NOT EXISTS twitter (\n",
    "                                        id integer PRIMARY KEY ASC,\n",
    "                                        twitter_json text NOT NULL\n",
    "                                    ); \"\"\"\n",
    "\n",
    "# Create the table\n",
    "create_table(c, sql_create_twitter_table)\n",
    "print(\"Table created\")\n",
    "\n",
    "# Verify that the table was created by querying what tables are in the database\n",
    "sql_tables_query = \"\"\"SELECT name FROM sqlite_master WHERE type='table';\"\"\"\n",
    "c.execute(sql_tables_query)\n",
    "print(c.fetchall())\n",
    "\n",
    "# Close the connection to the database\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our database is created, we can store the twitter data in the database. Instead of using raw SQL commands, we are going to practice using SQLalchemy, a python library purpose built for managing multiple types of databases in a more efficient/safe manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "EntityBase = declarative_base()\n",
    "\n",
    "# Make sure the table and column names match the table already created\n",
    "class Item(EntityBase):\n",
    "    __tablename__ = \"twitter\"\n",
    "    id = Column(Integer, Sequence(\"item_id_seq\"), primary_key=True, nullable=False)\n",
    "    twitter_json = Column(JSON, nullable=True)\n",
    "\n",
    "# Setup a database connection.\n",
    "engine = create_engine(\"sqlite:///twitter.db\")\n",
    "\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "\n",
    "# You can create new tables using this line of code if desired\n",
    "#EntityBase.metadata.create_all(engine)\n",
    "\n",
    "# Declare a new row\n",
    "first_item = Item()\n",
    "first_item.twitter_json = twitter_response\n",
    "\n",
    "# Insert it into the database\n",
    "session.add(first_item)\n",
    "session.commit()\n",
    "\n",
    "# Close the session and dispose engine\n",
    "session.close()\n",
    "engine.dispose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 2: Clean Data\n",
    "\n",
    "We now have data streaming to a storage solution. Now we want to clean and format the data for the purposes of our application. We want to understand and visualize what people are saying about our topic of choice, so in this section we will preprocess the tweets, perform named entity recognition, sentiment analysis, and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy as db\n",
    "import nltk\n",
    "# The first time you run this cell, you may need to execute the following two lines\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('all')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, '{\"data\": [{\"text\": \"@savanha_2012 @Josh_Snyder11 Saw a tweet earlier that said girl Mahomes looks like she runs a captain Ds like it\\\\u2019s the Navy ... (108277 characters truncated) ... _id\": \"1593393545649557505\", \"oldest_id\": \"1593391893139755009\", \"result_count\": 100, \"next_token\": \"b26v89c19zqg8o3fpzhkh9u1zfboor10bhvrkgrbedlrx\"}}')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query all data from the database using sqlalchemy\n",
    "\n",
    "engine = db.create_engine('sqlite:///twitter.db')\n",
    "connection = engine.connect()\n",
    "metadata = db.MetaData()\n",
    "twitter = db.Table('twitter', metadata, autoload=True, autoload_with=engine)\n",
    "\n",
    "# Equivalent to \"SELECT * FROM twitter\"\n",
    "query = db.select([twitter])\n",
    "ResultProxy = connection.execute(query)\n",
    "ResultSet = ResultProxy.fetchall()\n",
    "\n",
    "ResultSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>twitter_json</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>{'data': [{'text': '@savanha_2012 @Josh_Snyder...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                       twitter_json\n",
       "0   1  {'data': [{'text': '@savanha_2012 @Josh_Snyder..."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the results to a dataframe, convert the data column back to json from string\n",
    "\n",
    "df = pd.DataFrame(ResultSet)\n",
    "df.columns = ResultSet[0].keys()\n",
    "df[\"twitter_json\"] = df[\"twitter_json\"].apply(json.loads) \n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>tweet_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@savanha_2012 @Josh_Snyder11 Saw a tweet earli...</td>\n",
       "      <td>2022-11-17T23:59:59.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @ToddGloria: History in the making! Honored...</td>\n",
       "      <td>2022-11-17T23:59:59.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>お待たせしております、Beersシャツの予約開始です！\\nカラーはBLACK、NAVY、WI...</td>\n",
       "      <td>2022-11-17T23:59:57.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>new challenge just dropped: try to make a swif...</td>\n",
       "      <td>2022-11-17T23:59:55.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @USNavy: The #EOD Team assigned to Carrier ...</td>\n",
       "      <td>2022-11-17T23:59:43.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>RT @larwoolf: Rock Hudson \\nNovember 17, 1925 ...</td>\n",
       "      <td>2022-11-17T23:53:34.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>RT @StephenM: If President Biden cared one bit...</td>\n",
       "      <td>2022-11-17T23:53:32.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>RT @Jaejeong0807: [Free Q&amp;amp;A session about ...</td>\n",
       "      <td>2022-11-17T23:53:28.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>@US_Navy_Ret_MD @Pazkc1971 Coast Guard has a f...</td>\n",
       "      <td>2022-11-17T23:53:27.000Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>@mirmops I bought from old navy and gap. They ...</td>\n",
       "      <td>2022-11-17T23:53:25.000Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           tweet_text  \\\n",
       "0   @savanha_2012 @Josh_Snyder11 Saw a tweet earli...   \n",
       "1   RT @ToddGloria: History in the making! Honored...   \n",
       "2   お待たせしております、Beersシャツの予約開始です！\\nカラーはBLACK、NAVY、WI...   \n",
       "3   new challenge just dropped: try to make a swif...   \n",
       "4   RT @USNavy: The #EOD Team assigned to Carrier ...   \n",
       "..                                                ...   \n",
       "95  RT @larwoolf: Rock Hudson \\nNovember 17, 1925 ...   \n",
       "96  RT @StephenM: If President Biden cared one bit...   \n",
       "97  RT @Jaejeong0807: [Free Q&amp;A session about ...   \n",
       "98  @US_Navy_Ret_MD @Pazkc1971 Coast Guard has a f...   \n",
       "99  @mirmops I bought from old navy and gap. They ...   \n",
       "\n",
       "                  tweet_date  \n",
       "0   2022-11-17T23:59:59.000Z  \n",
       "1   2022-11-17T23:59:59.000Z  \n",
       "2   2022-11-17T23:59:57.000Z  \n",
       "3   2022-11-17T23:59:55.000Z  \n",
       "4   2022-11-17T23:59:43.000Z  \n",
       "..                       ...  \n",
       "95  2022-11-17T23:53:34.000Z  \n",
       "96  2022-11-17T23:53:32.000Z  \n",
       "97  2022-11-17T23:53:28.000Z  \n",
       "98  2022-11-17T23:53:27.000Z  \n",
       "99  2022-11-17T23:53:25.000Z  \n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iterate through the dataframe and pull out all of the text from the tweets and the dates\n",
    "\n",
    "tweet_text = []\n",
    "for row in df[\"twitter_json\"]:\n",
    "    for tweet in row[\"data\"]:\n",
    "        tweet_text.append((tweet[\"text\"],tweet[\"created_at\"]))\n",
    "\n",
    "tweet_df = pd.DataFrame(tweet_text,columns=[\"tweet_text\", \"tweet_date\"])\n",
    "\n",
    "tweet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>tweet_date</th>\n",
       "      <th>tweet_text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@savanha_2012 @Josh_Snyder11 Saw a tweet earli...</td>\n",
       "      <td>2022-11-17T23:59:59.000Z</td>\n",
       "      <td>[saw, tweet, earlier, said, girl, mahomes, loo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @ToddGloria: History in the making! Honored...</td>\n",
       "      <td>2022-11-17T23:59:59.000Z</td>\n",
       "      <td>[history, making, honored, join, fellow, san, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>お待たせしております、Beersシャツの予約開始です！\\nカラーはBLACK、NAVY、WI...</td>\n",
       "      <td>2022-11-17T23:59:57.000Z</td>\n",
       "      <td>[beersblacknavywine, red, 3black, bot]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>new challenge just dropped: try to make a swif...</td>\n",
       "      <td>2022-11-17T23:59:55.000Z</td>\n",
       "      <td>[new, challenge, dropped, try, make, swiftie, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @USNavy: The #EOD Team assigned to Carrier ...</td>\n",
       "      <td>2022-11-17T23:59:43.000Z</td>\n",
       "      <td>[team, assigned, carrier, strike, group, took,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>RT @larwoolf: Rock Hudson \\nNovember 17, 1925 ...</td>\n",
       "      <td>2022-11-17T23:53:34.000Z</td>\n",
       "      <td>[rock, hudson, november, october, first, scree...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>RT @StephenM: If President Biden cared one bit...</td>\n",
       "      <td>2022-11-17T23:53:32.000Z</td>\n",
       "      <td>[president, biden, cared, one, bit, sovereignt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>RT @Jaejeong0807: [Free Q&amp;amp;A session about ...</td>\n",
       "      <td>2022-11-17T23:53:28.000Z</td>\n",
       "      <td>[free, q, session, korean, military, hi, army,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>@US_Navy_Ret_MD @Pazkc1971 Coast Guard has a f...</td>\n",
       "      <td>2022-11-17T23:53:27.000Z</td>\n",
       "      <td>[coast, guard, ha, full, deck, puerto, rico, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>@mirmops I bought from old navy and gap. They ...</td>\n",
       "      <td>2022-11-17T23:53:25.000Z</td>\n",
       "      <td>[bought, old, gap, equally, bad]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           tweet_text  \\\n",
       "0   @savanha_2012 @Josh_Snyder11 Saw a tweet earli...   \n",
       "1   RT @ToddGloria: History in the making! Honored...   \n",
       "2   お待たせしております、Beersシャツの予約開始です！\\nカラーはBLACK、NAVY、WI...   \n",
       "3   new challenge just dropped: try to make a swif...   \n",
       "4   RT @USNavy: The #EOD Team assigned to Carrier ...   \n",
       "..                                                ...   \n",
       "95  RT @larwoolf: Rock Hudson \\nNovember 17, 1925 ...   \n",
       "96  RT @StephenM: If President Biden cared one bit...   \n",
       "97  RT @Jaejeong0807: [Free Q&amp;A session about ...   \n",
       "98  @US_Navy_Ret_MD @Pazkc1971 Coast Guard has a f...   \n",
       "99  @mirmops I bought from old navy and gap. They ...   \n",
       "\n",
       "                  tweet_date  \\\n",
       "0   2022-11-17T23:59:59.000Z   \n",
       "1   2022-11-17T23:59:59.000Z   \n",
       "2   2022-11-17T23:59:57.000Z   \n",
       "3   2022-11-17T23:59:55.000Z   \n",
       "4   2022-11-17T23:59:43.000Z   \n",
       "..                       ...   \n",
       "95  2022-11-17T23:53:34.000Z   \n",
       "96  2022-11-17T23:53:32.000Z   \n",
       "97  2022-11-17T23:53:28.000Z   \n",
       "98  2022-11-17T23:53:27.000Z   \n",
       "99  2022-11-17T23:53:25.000Z   \n",
       "\n",
       "                                     tweet_text_clean  \n",
       "0   [saw, tweet, earlier, said, girl, mahomes, loo...  \n",
       "1   [history, making, honored, join, fellow, san, ...  \n",
       "2              [beersblacknavywine, red, 3black, bot]  \n",
       "3   [new, challenge, dropped, try, make, swiftie, ...  \n",
       "4   [team, assigned, carrier, strike, group, took,...  \n",
       "..                                                ...  \n",
       "95  [rock, hudson, november, october, first, scree...  \n",
       "96  [president, biden, cared, one, bit, sovereignt...  \n",
       "97  [free, q, session, korean, military, hi, army,...  \n",
       "98  [coast, guard, ha, full, deck, puerto, rico, w...  \n",
       "99                   [bought, old, gap, equally, bad]  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can clean the text up a bit, so we will use a series of NLP preprocessing techniques to do so\n",
    "\n",
    "# https://towardsdatascience.com/basic-tweet-preprocessing-in-python-efd8360d529\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "w_tokenizer = TweetTokenizer()\n",
    "import preprocessor as p\n",
    "import re\n",
    "\n",
    "# Figure out how to keep hashtags\n",
    "# Perform named entity recognition\n",
    "\n",
    "# Before we clean up the tweets entirely, we want to make sure that we are keeping the \n",
    "# named entities and hashtags intact, so we will pull those out of the tweets first\n",
    "\n",
    "def preprocesss_tweet(input_text):\n",
    "    \n",
    "    def remove_punctuation(words):\n",
    "        new_words = []\n",
    "        for word in words:\n",
    "            new_word = re.sub(r'[^\\w\\s]', '', (word))\n",
    "            if new_word != '':\n",
    "                new_words.append(new_word)\n",
    "        return new_words\n",
    "\n",
    "    input_text = p.clean(input_text)\n",
    "\n",
    "    input_text = input_text.replace('\\d+', '')\n",
    "    input_text = input_text.lower()\n",
    "\n",
    "    input_text = [(lemmatizer.lemmatize(w)) for w in \\\n",
    "                                            w_tokenizer.tokenize((input_text))]\n",
    "    \n",
    "    input_text = remove_punctuation(input_text)\n",
    "    \n",
    "    stop_words = stopwords.words('english')\n",
    "\n",
    "    new_stopwords = [\"navy\"]\n",
    "    stop_words.extend(new_stopwords)\n",
    "\n",
    "    filtered_sentence = [item for item in input_text if item not in stop_words]\n",
    "\n",
    "    return filtered_sentence\n",
    "\n",
    "tweet_df[\"tweet_text_clean\"] = tweet_df[\"tweet_text\"].apply(preprocesss_tweet)\n",
    "\n",
    "tweet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6605/373170249.py:4: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  word_counts = pd.value_counts(tweet_df[\"tweet_text_clean\"].apply(pd.Series).stack())\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wa</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>qatar</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>like</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>check</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>code</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>gerade</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>exetlos</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>continue</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>bad</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>672 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        words  weights\n",
       "0           u       16\n",
       "1          wa       12\n",
       "2       qatar       10\n",
       "3        like       10\n",
       "4       check        9\n",
       "..        ...      ...\n",
       "667      code        1\n",
       "668    gerade        1\n",
       "669   exetlos        1\n",
       "670  continue        1\n",
       "671       bad        1\n",
       "\n",
       "[672 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now were going to break up the words and count each occurrence of words\n",
    "\n",
    "#words = tweet_text_clean.str.split()\n",
    "word_counts = pd.value_counts(tweet_df[\"tweet_text_clean\"].apply(pd.Series).stack())\n",
    "word_counts = pd.Series(word_counts)\n",
    "word_df = pd.DataFrame({'words':word_counts.index, 'weights':word_counts.values})\n",
    "\n",
    "word_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>weights</th>\n",
       "      <th>source_tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u</td>\n",
       "      <td>16</td>\n",
       "      <td>[JAG to Prosecute Deep Staters In-Absentia\\nTh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wa</td>\n",
       "      <td>12</td>\n",
       "      <td>[@Rowan_M72 It would be pretty funny if Presid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>qatar</td>\n",
       "      <td>10</td>\n",
       "      <td>[RT @NurulNurAriani1: Hindutva &amp;amp; Zionism n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>like</td>\n",
       "      <td>10</td>\n",
       "      <td>[@savanha_2012 @Josh_Snyder11 Saw a tweet earl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>check</td>\n",
       "      <td>9</td>\n",
       "      <td>[Check out this listing I just added to my #Po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>code</td>\n",
       "      <td>1</td>\n",
       "      <td>[gerade die Codes der \"Navy\" des deutschen Rei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>gerade</td>\n",
       "      <td>1</td>\n",
       "      <td>[gerade die Codes der \"Navy\" des deutschen Rei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>exetlos</td>\n",
       "      <td>1</td>\n",
       "      <td>[Christopher Cleary Talks Navy Cyber Strategy,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>continue</td>\n",
       "      <td>1</td>\n",
       "      <td>[Christopher Cleary Talks Navy Cyber Strategy,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>bad</td>\n",
       "      <td>1</td>\n",
       "      <td>[@mirmops I bought from old navy and gap. They...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>672 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        words  weights                                      source_tweets\n",
       "0           u       16  [JAG to Prosecute Deep Staters In-Absentia\\nTh...\n",
       "1          wa       12  [@Rowan_M72 It would be pretty funny if Presid...\n",
       "2       qatar       10  [RT @NurulNurAriani1: Hindutva &amp; Zionism n...\n",
       "3        like       10  [@savanha_2012 @Josh_Snyder11 Saw a tweet earl...\n",
       "4       check        9  [Check out this listing I just added to my #Po...\n",
       "..        ...      ...                                                ...\n",
       "667      code        1  [gerade die Codes der \"Navy\" des deutschen Rei...\n",
       "668    gerade        1  [gerade die Codes der \"Navy\" des deutschen Rei...\n",
       "669   exetlos        1  [Christopher Cleary Talks Navy Cyber Strategy,...\n",
       "670  continue        1  [Christopher Cleary Talks Navy Cyber Strategy,...\n",
       "671       bad        1  [@mirmops I bought from old navy and gap. They...\n",
       "\n",
       "[672 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep which tweets contain those words\n",
    "# Change this to somehow reference the tweet dataframe, but needs to be linked in the database this way\n",
    "\n",
    "def find_tweets(word, tweet_df):\n",
    "    tweet_list = []\n",
    "\n",
    "    for index, row in tweet_df.iterrows():\n",
    "        if word in row[\"tweet_text_clean\"]:\n",
    "            tweet_list.append(row[\"tweet_text\"])\n",
    "    \n",
    "    return tweet_list\n",
    "\n",
    "word_df[\"source_tweets\"] = word_df[\"words\"].apply(lambda x: find_tweets(x, tweet_df))\n",
    "\n",
    "word_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We also will want to see sentiment analysis of what people are saying about the Navy\n",
    "# Here we will use a pre-trained sentiment analysis model from Huggingface \n",
    "\n",
    "# https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment?text=I+like+you.+I+love+you\n",
    "\n",
    "# Use model pretrained on tweets\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "import csv\n",
    "import urllib.request\n",
    "\n",
    "def preprocess(text):\n",
    "    new_text = []\n",
    "    for t in text.split(\" \"):\n",
    "        t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
    "        t = 'http' if t.startswith('http') else t\n",
    "        new_text.append(t)\n",
    "    return \" \".join(new_text)\n",
    "\n",
    "def classify_tweet(model, tokenizer, task, text):\n",
    "    labels=[]\n",
    "    mapping_link = f\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/{task}/mapping.txt\"\n",
    "    with urllib.request.urlopen(mapping_link) as f:\n",
    "        html = f.read().decode('utf-8').split(\"\\n\")\n",
    "        csvreader = csv.reader(html, delimiter='\\t')\n",
    "    labels = [row[1] for row in csvreader if len(row)>1]\n",
    "\n",
    "    text = preprocess(text)\n",
    "    encoded_input = tokenizer(text, return_tensors='pt')\n",
    "    output = model(**encoded_input)\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "\n",
    "    ranking = np.argsort(scores)\n",
    "    ranking = ranking[::-1]\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for i in range(scores.shape[0]):\n",
    "        l = labels[ranking[i]]\n",
    "        s = scores[ranking[i]]\n",
    "        #print(f\"{i+1}) {l} {np.round(float(s), 4)}\")\n",
    "        results[f\"{l}\"]=np.round(float(s), 4)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>tweet_date</th>\n",
       "      <th>tweet_text_clean</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@savanha_2012 @Josh_Snyder11 Saw a tweet earli...</td>\n",
       "      <td>2022-11-17T23:59:59.000Z</td>\n",
       "      <td>[saw, tweet, earlier, said, girl, mahomes, loo...</td>\n",
       "      <td>{'neutral': 0.6704, 'negative': 0.2093, 'posit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @ToddGloria: History in the making! Honored...</td>\n",
       "      <td>2022-11-17T23:59:59.000Z</td>\n",
       "      <td>[history, making, honored, join, fellow, san, ...</td>\n",
       "      <td>{'positive': 0.9578, 'neutral': 0.0415, 'negat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>お待たせしております、Beersシャツの予約開始です！\\nカラーはBLACK、NAVY、WI...</td>\n",
       "      <td>2022-11-17T23:59:57.000Z</td>\n",
       "      <td>[beersblacknavywine, red, 3black, bot]</td>\n",
       "      <td>{'neutral': 0.7031, 'negative': 0.256, 'positi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>new challenge just dropped: try to make a swif...</td>\n",
       "      <td>2022-11-17T23:59:55.000Z</td>\n",
       "      <td>[new, challenge, dropped, try, make, swiftie, ...</td>\n",
       "      <td>{'negative': 0.5166, 'neutral': 0.4032, 'posit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @USNavy: The #EOD Team assigned to Carrier ...</td>\n",
       "      <td>2022-11-17T23:59:43.000Z</td>\n",
       "      <td>[team, assigned, carrier, strike, group, took,...</td>\n",
       "      <td>{'neutral': 0.9194, 'negative': 0.0479, 'posit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>RT @larwoolf: Rock Hudson \\nNovember 17, 1925 ...</td>\n",
       "      <td>2022-11-17T23:53:34.000Z</td>\n",
       "      <td>[rock, hudson, november, october, first, scree...</td>\n",
       "      <td>{'neutral': 0.9047, 'negative': 0.0605, 'posit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>RT @StephenM: If President Biden cared one bit...</td>\n",
       "      <td>2022-11-17T23:53:32.000Z</td>\n",
       "      <td>[president, biden, cared, one, bit, sovereignt...</td>\n",
       "      <td>{'negative': 0.5236, 'neutral': 0.4374, 'posit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>RT @Jaejeong0807: [Free Q&amp;amp;A session about ...</td>\n",
       "      <td>2022-11-17T23:53:28.000Z</td>\n",
       "      <td>[free, q, session, korean, military, hi, army,...</td>\n",
       "      <td>{'neutral': 0.7131, 'positive': 0.2166, 'negat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>@US_Navy_Ret_MD @Pazkc1971 Coast Guard has a f...</td>\n",
       "      <td>2022-11-17T23:53:27.000Z</td>\n",
       "      <td>[coast, guard, ha, full, deck, puerto, rico, w...</td>\n",
       "      <td>{'neutral': 0.5943, 'negative': 0.3517, 'posit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>@mirmops I bought from old navy and gap. They ...</td>\n",
       "      <td>2022-11-17T23:53:25.000Z</td>\n",
       "      <td>[bought, old, gap, equally, bad]</td>\n",
       "      <td>{'negative': 0.9342, 'neutral': 0.0607, 'posit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           tweet_text  \\\n",
       "0   @savanha_2012 @Josh_Snyder11 Saw a tweet earli...   \n",
       "1   RT @ToddGloria: History in the making! Honored...   \n",
       "2   お待たせしております、Beersシャツの予約開始です！\\nカラーはBLACK、NAVY、WI...   \n",
       "3   new challenge just dropped: try to make a swif...   \n",
       "4   RT @USNavy: The #EOD Team assigned to Carrier ...   \n",
       "..                                                ...   \n",
       "95  RT @larwoolf: Rock Hudson \\nNovember 17, 1925 ...   \n",
       "96  RT @StephenM: If President Biden cared one bit...   \n",
       "97  RT @Jaejeong0807: [Free Q&amp;A session about ...   \n",
       "98  @US_Navy_Ret_MD @Pazkc1971 Coast Guard has a f...   \n",
       "99  @mirmops I bought from old navy and gap. They ...   \n",
       "\n",
       "                  tweet_date  \\\n",
       "0   2022-11-17T23:59:59.000Z   \n",
       "1   2022-11-17T23:59:59.000Z   \n",
       "2   2022-11-17T23:59:57.000Z   \n",
       "3   2022-11-17T23:59:55.000Z   \n",
       "4   2022-11-17T23:59:43.000Z   \n",
       "..                       ...   \n",
       "95  2022-11-17T23:53:34.000Z   \n",
       "96  2022-11-17T23:53:32.000Z   \n",
       "97  2022-11-17T23:53:28.000Z   \n",
       "98  2022-11-17T23:53:27.000Z   \n",
       "99  2022-11-17T23:53:25.000Z   \n",
       "\n",
       "                                     tweet_text_clean  \\\n",
       "0   [saw, tweet, earlier, said, girl, mahomes, loo...   \n",
       "1   [history, making, honored, join, fellow, san, ...   \n",
       "2              [beersblacknavywine, red, 3black, bot]   \n",
       "3   [new, challenge, dropped, try, make, swiftie, ...   \n",
       "4   [team, assigned, carrier, strike, group, took,...   \n",
       "..                                                ...   \n",
       "95  [rock, hudson, november, october, first, scree...   \n",
       "96  [president, biden, cared, one, bit, sovereignt...   \n",
       "97  [free, q, session, korean, military, hi, army,...   \n",
       "98  [coast, guard, ha, full, deck, puerto, rico, w...   \n",
       "99                   [bought, old, gap, equally, bad]   \n",
       "\n",
       "                                            sentiment  \n",
       "0   {'neutral': 0.6704, 'negative': 0.2093, 'posit...  \n",
       "1   {'positive': 0.9578, 'neutral': 0.0415, 'negat...  \n",
       "2   {'neutral': 0.7031, 'negative': 0.256, 'positi...  \n",
       "3   {'negative': 0.5166, 'neutral': 0.4032, 'posit...  \n",
       "4   {'neutral': 0.9194, 'negative': 0.0479, 'posit...  \n",
       "..                                                ...  \n",
       "95  {'neutral': 0.9047, 'negative': 0.0605, 'posit...  \n",
       "96  {'negative': 0.5236, 'neutral': 0.4374, 'posit...  \n",
       "97  {'neutral': 0.7131, 'positive': 0.2166, 'negat...  \n",
       "98  {'neutral': 0.5943, 'negative': 0.3517, 'posit...  \n",
       "99  {'negative': 0.9342, 'neutral': 0.0607, 'posit...  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tasks:\n",
    "# emoji, emotion, hate, irony, offensive, sentiment\n",
    "# stance/abortion, stance/atheism, stance/climate, stance/feminist, stance/hillary\n",
    "\n",
    "task='sentiment'\n",
    "MODEL = f\"cardiffnlp/twitter-roberta-base-{task}\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "#model.save_pretrained(MODEL)\n",
    "\n",
    "tweet_df[\"sentiment\"] = tweet_df['tweet_text'].apply(lambda x: classify_tweet(model, tokenizer, task, x))\n",
    "\n",
    "tweet_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have cleaned the data, we will store it all back into the database for easy access by our application and to minimize the amount of processing required for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store data in database with Pandas\n",
    "\n",
    "# We will have two tables, one being word counts and the other being sentiment\n",
    "# The storage could be more efficient, as we are storing our tweets twice in this format, but those are improvements we \n",
    "# can make in the future\n",
    "# https://hackersandslackers.com/connecting-pandas-to-a-sql-database-with-sqlalchemy/\n",
    "\n",
    "from sqlalchemy.types import Integer, Text, String, DateTime\n",
    "\n",
    "tweet_df = tweet_df.astype(str)\n",
    "word_df = word_df.astype(str)\n",
    "\n",
    "tweet_df.to_sql(\n",
    "    \"tweets\", \n",
    "    engine, \n",
    "    if_exists=\"replace\", \n",
    "    index=False, \n",
    "    chunksize=500, \n",
    "    dtype={\n",
    "        \"tweet_text\": Text,\n",
    "        \"tweet_date\": Text,\n",
    "        \"tweet_text_clean\": Text,\n",
    "        \"sentiment\": Text \n",
    "        }\n",
    "    )\n",
    "\n",
    "word_df.to_sql(\n",
    "    \"words\",\n",
    "    engine,\n",
    "    if_exists=\"replace\",\n",
    "    index=False,\n",
    "    chunksize=500,\n",
    "    dtype={\n",
    "        \"words\": Text,\n",
    "        \"weights\": Integer,\n",
    "        \"source_tweets\": Text\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the session and dispose engine\n",
    "connection.close()\n",
    "engine.dispose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 3: Front end application\n",
    "\n",
    "Now that we have our raw and cleaned data in a database, we can work on the web application to visualize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          tweet_text  \\\n",
      "0  @savanha_2012 @Josh_Snyder11 Saw a tweet earli...   \n",
      "1  RT @ToddGloria: History in the making! Honored...   \n",
      "2  お待たせしております、Beersシャツの予約開始です！\\nカラーはBLACK、NAVY、WI...   \n",
      "3  new challenge just dropped: try to make a swif...   \n",
      "4  RT @USNavy: The #EOD Team assigned to Carrier ...   \n",
      "\n",
      "                 tweet_date  \\\n",
      "0 2022-11-17 23:59:59+00:00   \n",
      "1 2022-11-17 23:59:59+00:00   \n",
      "2 2022-11-17 23:59:57+00:00   \n",
      "3 2022-11-17 23:59:55+00:00   \n",
      "4 2022-11-17 23:59:43+00:00   \n",
      "\n",
      "                                    tweet_text_clean  \\\n",
      "0  ['saw', 'tweet', 'earlier', 'said', 'girl', 'm...   \n",
      "1  ['history', 'making', 'honored', 'join', 'fell...   \n",
      "2     ['beersblacknavywine', 'red', '3black', 'bot']   \n",
      "3  ['new', 'challenge', 'dropped', 'try', 'make',...   \n",
      "4  ['team', 'assigned', 'carrier', 'strike', 'gro...   \n",
      "\n",
      "                                           sentiment sentiment_final  \n",
      "0  {'neutral': 0.6704, 'negative': 0.2093, 'posit...         neutral  \n",
      "1  {'positive': 0.9578, 'neutral': 0.0415, 'negat...        positive  \n",
      "2  {'neutral': 0.7031, 'negative': 0.256, 'positi...         neutral  \n",
      "3  {'negative': 0.5166, 'neutral': 0.4032, 'posit...        negative  \n",
      "4  {'neutral': 0.9194, 'negative': 0.0479, 'posit...         neutral  \n",
      "   words  weights                                      source_tweets\n",
      "0      u       16  ['JAG to Prosecute Deep Staters In-Absentia\\nT...\n",
      "1     wa       12  ['@Rowan_M72 It would be pretty funny if Presi...\n",
      "2  qatar       10  ['RT @NurulNurAriani1: Hindutva &amp; Zionism ...\n",
      "3   like       10  ['@savanha_2012 @Josh_Snyder11 Saw a tweet ear...\n",
      "4  check        9  ['Check out this listing I just added to my #P...\n"
     ]
    }
   ],
   "source": [
    "# Query data we want to visualize\n",
    "\n",
    "import sqlalchemy as db\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "engine = db.create_engine('sqlite:///twitter.db')\n",
    "connection = engine.connect()\n",
    "\n",
    "def sentiment_score(scores):\n",
    "    sentiment = max(scores, key=scores.get)\n",
    "    return sentiment\n",
    "\n",
    "tweet_df = pd.read_sql_table('tweets', engine) \n",
    "tweet_df['sentiment'] = tweet_df['sentiment'].str.replace(\"'\", '\"')\n",
    "tweet_df['sentiment'] = tweet_df['sentiment'].apply(json.loads) \n",
    "tweet_df['sentiment_final'] = tweet_df['sentiment'].apply(sentiment_score)\n",
    "tweet_df['tweet_date'] = pd.to_datetime(tweet_df['tweet_date'])\n",
    "word_df = pd.read_sql_table('words', engine) \n",
    "\n",
    "print(tweet_df.head())\n",
    "print(word_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_date</th>\n",
       "      <th>positive</th>\n",
       "      <th>neutral</th>\n",
       "      <th>negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-11-17 23:53:00+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-11-17 23:54:00+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-11-17 23:55:00+00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-11-17 23:56:00+00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-11-17 23:57:00+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-11-17 23:58:00+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-11-17 23:59:00+00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 tweet_date positive neutral negative\n",
       "0 2022-11-17 23:53:00+00:00        0       6        2\n",
       "0 2022-11-17 23:54:00+00:00        1      14        2\n",
       "0 2022-11-17 23:55:00+00:00        2       8        1\n",
       "0 2022-11-17 23:56:00+00:00        2       8        3\n",
       "0 2022-11-17 23:57:00+00:00        1      13        3\n",
       "0 2022-11-17 23:58:00+00:00        1       9        4\n",
       "0 2022-11-17 23:59:00+00:00        5      14        1"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create dataframe with sentiment count by date group (default group by minute) \n",
    "\n",
    "date_group_tweet_df = tweet_df[[\"tweet_date\", \"sentiment_final\"]].groupby(pd.Grouper(key='tweet_date', axis=0, \n",
    "                      freq='1min', sort=True))\n",
    "sentiment_time_df = pd.DataFrame(columns=[\"tweet_date\", \"positive\", \"neutral\", \"negative\"])\n",
    "sentiment_labels = [\"positive\", \"neutral\", \"negative\"]\n",
    "\n",
    "for key, item in date_group_tweet_df:\n",
    "    temp_df = pd.DataFrame()\n",
    "    group = date_group_tweet_df.get_group(key)\n",
    "    sentiment_values = pd.Series(group['sentiment_final'].value_counts())\n",
    "    values_df = pd.DataFrame(data=[sentiment_values.values], columns=sentiment_values.index)\n",
    "\n",
    "    # Fill in sentiment as 0 for any missing values\n",
    "    missing_values = set(sentiment_labels).difference(values_df.columns)\n",
    "    if len(missing_values) > 0:\n",
    "        for i in missing_values:\n",
    "            values_df[i]=0\n",
    "    \n",
    "    # Combine the date value to the minute and the value counts\n",
    "    date = group[\"tweet_date\"].dt.floor('Min').reset_index(drop=True)[0]\n",
    "    values_df[\"tweet_date\"] = date\n",
    "\n",
    "    # Append value to dataframe\n",
    "    sentiment_time_df = pd.concat([sentiment_time_df, values_df], axis=0)\n",
    "\n",
    "sentiment_time_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:8050\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [20/Nov/2022 15:11:51] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [20/Nov/2022 15:11:52] \"GET /_dash-layout HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [20/Nov/2022 15:11:52] \"GET /_dash-dependencies HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [20/Nov/2022 15:11:52] \"GET /_favicon.ico?v=2.7.0 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [20/Nov/2022 15:11:52] \"GET /_dash-component-suites/dash/dcc/async-graph.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [20/Nov/2022 15:11:52] \"GET /_dash-component-suites/dash/dcc/async-plotlyjs.js HTTP/1.1\" 304 -\n",
      "127.0.0.1 - - [20/Nov/2022 15:11:53] \"GET /_favicon.ico?v=2.7.0 HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [20/Nov/2022 15:11:54] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [20/Nov/2022 15:11:55] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [20/Nov/2022 15:11:55] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [20/Nov/2022 15:11:55] \"POST /_dash-update-component HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "# This is an app built in Dash, which is built on top of Flask and Plotly.js\n",
    "# It is preferable to run this from a .py file, but for ease, I am including it in the Jupyter notebook\n",
    "# You will need to kill the Jupyter kernel in order to stop the process running\n",
    "\n",
    "# To kill the process, if running this in vscode, go to the Ports tab, hover over the process running 8050 and note \n",
    "# the process id. Then go to the terminal and type kill -9 <INSERT PID>\n",
    "# Restart the jupyter kernel and you should be able to ezecute the code again\n",
    "\n",
    "import dash\n",
    "from dash import html\n",
    "from dash import dcc\n",
    "import dash_bootstrap_components as dbc\n",
    "import plotly.express as px\n",
    "from dash.dependencies import Input, Output\n",
    "import dash_bootstrap_components as dbc\n",
    "import plotly.graph_objects as go\n",
    "from io import BytesIO\n",
    "from wordcloud import WordCloud\n",
    "import base64\n",
    "import dash.dependencies as dd\n",
    "\n",
    "app = dash.Dash(__name__,external_stylesheets=[dbc.themes.LUX])\n",
    "app.layout = html.Div([\n",
    "    html.H1('Twitter Analytics - \"Navy\"',className='text-center'),\n",
    "    dbc.Row([\n",
    "        dbc.Col([\n",
    "            dbc.Card([\n",
    "                dbc.CardBody([\n",
    "                    html.H5('Word Cloud',className='text-center'),\n",
    "                    html.Img(id=\"image_wc\"),\n",
    "                ])\n",
    "            ])\n",
    "        ],width={'size':12,\"offset\":0,'order':1},style={'padding-left' : 25,'padding-right' : 25},className='text-center'),\n",
    "    ]),\n",
    "    dbc.Row([\n",
    "        dbc.Col([\n",
    "            dbc.Card([\n",
    "                dbc.CardBody([\n",
    "                    html.H5('Word Bar Chart',className='text-center'),\n",
    "                    dcc.Graph(id=\"image_wbc\"),\n",
    "                ])\n",
    "            ])\n",
    "        ],width={'size':12,\"offset\":0,'order':1},style={'padding-left' : 25,'padding-right' : 25},className='text-center'),\n",
    "    ]),\n",
    "    dbc.Row([\n",
    "        dbc.Col([\n",
    "            dbc.Card([\n",
    "                dbc.CardBody([\n",
    "                    html.H5('Sentiment Analysis Chart',className='text-center'),\n",
    "                    dcc.Graph(id=\"image_sac\"),\n",
    "                ])\n",
    "            ])\n",
    "        ],width={'size':12,\"offset\":0,'order':1},style={'padding-left' : 25,'padding-right' : 25},className='text-center'),\n",
    "    ]),\n",
    "    dbc.Row([\n",
    "        dbc.Col([\n",
    "            dbc.Card([\n",
    "                dbc.CardBody([\n",
    "                    html.H5('Sentiment Analysis Timeline',className='text-center'),\n",
    "                    dcc.Graph(id=\"image_sat\"),\n",
    "                ])\n",
    "            ])\n",
    "        ],width={'size':12,\"offset\":0,'order':1},style={'padding-left' : 25,'padding-right' : 25},className='text-center'),\n",
    "    ])\n",
    "])\n",
    "\n",
    "# Plot Word Cloud\n",
    "def plot_wordcloud(data):\n",
    "    #d = {a: x for a, x in data.values}\n",
    "\n",
    "    data = data.set_index('words').to_dict()['weights']\n",
    "\n",
    "    wc = WordCloud(width=800, height=400, max_words=200).generate_from_frequencies(data)\n",
    "    #wc = WordCloud(background_color='white', width=1080, height=360)\n",
    "    #wc.fit_words(d)\n",
    "    return wc.to_image()\n",
    "\n",
    "# Plot bar chart of word count with mouseover for source tweets\n",
    "def plot_word_chart(data):\n",
    "    fig = px.bar(data, x='words', y='weights', hover_data=['source_tweets'])\n",
    "    return fig\n",
    "\n",
    "# Plot bar chart of sentiment analysis\n",
    "def plot_sentiment_chart(data):\n",
    "    sentiment = data['sentiment_final'].value_counts(normalize=True) * 100\n",
    "    sentiment_df = pd.DataFrame({'sentiment':sentiment.index, 'proportion':sentiment.values})\n",
    "    fig = px.bar(sentiment_df, x='sentiment', y='proportion')\n",
    "    return fig\n",
    "\n",
    "# Plot timeline of sentiment analysis\n",
    "def plot_sentiment_timeline(data):\n",
    "    # Create dataframe with sentiment count by date group (default group by minute) \n",
    "\n",
    "    date_group_tweet_df = data[[\"tweet_date\", \"sentiment_final\"]].groupby(pd.Grouper(key='tweet_date', axis=0, \n",
    "                        freq='1min', sort=True))\n",
    "\n",
    "    sentiment_time_df = pd.DataFrame(columns=[\"tweet_date\", \"positive\", \"neutral\", \"negative\"])\n",
    "\n",
    "    sentiment_labels = [\"positive\", \"neutral\", \"negative\"]\n",
    "\n",
    "    for key, item in date_group_tweet_df:\n",
    "        temp_df = pd.DataFrame()\n",
    "        group = date_group_tweet_df.get_group(key)\n",
    "        sentiment_values = pd.Series(group['sentiment_final'].value_counts())\n",
    "\n",
    "        values_df = pd.DataFrame(data=[sentiment_values.values], columns=sentiment_values.index)\n",
    "\n",
    "        # Fill in sentiment as 0 for any missing values\n",
    "        missing_values = set(sentiment_labels).difference(values_df.columns)\n",
    "        if len(missing_values) > 0:\n",
    "            for i in missing_values:\n",
    "                values_df[i]=0\n",
    "        \n",
    "        # Combine the date value to the minute and the value counts\n",
    "        date = group[\"tweet_date\"].dt.floor('Min').reset_index(drop=True)[0]\n",
    "\n",
    "        values_df[\"tweet_date\"] = date\n",
    "\n",
    "        # Append value to dataframe\n",
    "        sentiment_time_df = pd.concat([sentiment_time_df, values_df], axis=0)\n",
    "\n",
    "    fig = px.line(sentiment_time_df, x='tweet_date', y=sentiment_labels)\n",
    "    return fig\n",
    "\n",
    "# This will keep the image updated if the data changes for a continuous stream\n",
    "@app.callback(dd.Output('image_wc', 'src'), [dd.Input('image_wc', 'id')])\n",
    "def make_image(b):\n",
    "    img = BytesIO()\n",
    "    plot_wordcloud(data=word_df).save(img, format='PNG')\n",
    "    return 'data:image/png;base64,{}'.format(base64.b64encode(img.getvalue()).decode())\n",
    "   \n",
    "@app.callback(dd.Output('image_wbc', 'figure'), [dd.Input('image_wbc', 'id')])\n",
    "def make_word_chart(b):    \n",
    "    fig = plot_word_chart(word_df)\n",
    "    return fig\n",
    "\n",
    "@app.callback(dd.Output('image_sac', 'figure'), [dd.Input('image_sac', 'id')])\n",
    "def make_sentiment_chart(b):\n",
    "    fig = plot_sentiment_chart(tweet_df)\n",
    "    return fig\n",
    "\n",
    "@app.callback(dd.Output('image_sat', 'figure'), [dd.Input('image_sat', 'id')])\n",
    "def make_sentiment_timelin(b):\n",
    "    fig = plot_sentiment_timeline(tweet_df)\n",
    "    return fig\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run_server(debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute this cell to create a requirements.txt from the jupyter notebook in order to recreate the project easily\n",
    "\n",
    "!pip install pipreqs\n",
    "!pip install nbconvert\n",
    "!jupyter nbconvert --output-dir=\"./reqs\" --to script twitter-bokeh.ipynb\n",
    "!cd reqs\n",
    "!pipreqs --force"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! Now you should understand the basic framework of how raw data can be streamed and converted into a product for an end user. In Part 2, we preprocessed and cleaned the data to store it in a database in a structured manner. Then in Part 3 we visualized the data and in a web application to serve as a decision aid. \n",
    "\n",
    "With some slight modifications, this code can be updated to run live on a cloud platform of your choice with 3 instances. Part 1 would run to stream tweets on a periodic interval to a database. Part two would then trigger to continuously clean the data and perform sentiment analysis. Part three would continuously query the database to update the live visualizations in the web application."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ad933181bd8a04b432d3370b9dc3b0662ad032c4dfaa4e4f1596c548f763858"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
